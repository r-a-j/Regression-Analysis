---
title: "Project 3: Regression Analysis"
author: "Group 12 - Raj Anilbhai Pawar"
date: "`r Sys.Date()`"
output: html_document
---

### Clear memory
```{r}
rm(list=ls())
```

```{r}
library(readr)
library(ggplot2)
library(olsrr)
library(broom)
library(ggpubr)
```

### Data preparation
```{r}
bodymeasurements <- read_csv("bodymeasurements.csv", TRUE)
bodymeasurements <- as.data.frame(bodymeasurements)
head(bodymeasurements)

sum(is.na(bodymeasurements))
#0 missing values

drops <- c("ID")
bodymeasurements <-
  bodymeasurements[,!(names(bodymeasurements) %in% drops)]
```

### Descriptive Analysis
```{r}
sd(as.numeric(unlist(bodymeasurements["Height"])))
sd(as.numeric(unlist(bodymeasurements["Chest"])))
sd(as.numeric(unlist(bodymeasurements["Belly"])))
sd(as.numeric(unlist(bodymeasurements["Biceps"])))
sd(as.numeric(unlist(bodymeasurements["Knee"])))
sd(as.numeric(unlist(bodymeasurements["Ankle"])))
sd(as.numeric(unlist(bodymeasurements["Wrist"])))
sd(as.numeric(unlist(bodymeasurements["Thigh"])))
sd(as.numeric(unlist(bodymeasurements["Calf"])))
sd(as.numeric(unlist(bodymeasurements["Age"])))
sd(as.numeric(unlist(bodymeasurements["Weight"])))

# Check male female count
sum(bodymeasurements$Sex=='m')
sum(bodymeasurements$Sex=='f')

#summary(bodymeasurements)

weightPlt <- ggplot(bodymeasurements,
       aes(x = Weight , y = Height)) +
  geom_point() +
  xlab("Weight(Kgs)") +
  ylab("Height(cm)")

kneePlt <- ggplot(bodymeasurements,
       aes(x = Knee , y = Height)) +
  geom_point() +
  xlab("Knee(cm)") +
  ylab("Height(cm)")

wristPlt <- ggplot(bodymeasurements,
       aes(x = Wrist , y = Height)) +
  geom_point() +
  xlab("Wrist(cm)") +
  ylab("Height(cm)")

thighPlt <- ggplot(bodymeasurements,
       aes(x = Thigh , y = Height)) +
  geom_point() +
  xlab("Thigh(cm)") +
  ylab("Height(cm)")

bicepsPlt <- ggplot(bodymeasurements,
       aes(x = Biceps , y = Height)) +
  geom_point() +
  xlab("Biceps(cm)") +
  ylab("Height(cm)")

bellyPlt <- ggplot(bodymeasurements,
       aes(x = Belly , y = Height)) +
  geom_point() +
  xlab("Belly(cm)") +
  ylab("Height(cm)")

anklePlt <- ggplot(bodymeasurements,
       aes(x = Ankle , y = Height)) +
  geom_point() +
  xlab("Ankle(cm)") +
  ylab("Height(cm)")

chestPlt <- ggplot(bodymeasurements,
       aes(x = Chest , y = Height)) +
  geom_point() +
  xlab("Chest(cm)") +
  ylab("Height(cm)")

calfPlt <- ggplot(bodymeasurements,
       aes(x = Calf , y = Height)) +
  geom_point() +
  xlab("Calf(cm)") +
  ylab("Height(cm)")

agePlt <- ggplot(bodymeasurements,
       aes(x = Age , y = Height)) +
  geom_point() +
  xlab("Age(Years)") +
  ylab("Height(cm)")

# Scatter Plot of Height vs all covariates
figure <- ggarrange(weightPlt, kneePlt, wristPlt, thighPlt, bicepsPlt, bellyPlt, anklePlt, chestPlt, calfPlt, agePlt,
                    ncol = 5, nrow = 2)
figure

# Box plot for male and female vs height shows average height of males is greater than females
boxplot(Height ~ Sex, data = bodymeasurements, col = rainbow(ncol(trees)))
legend("topright", c("Female", "Male"), border="black", fill = c("Red", "Green"))

```



## Question 1:
### Determine a linear regression model that explains the body height based on all other given variables.

```{r}
fit_model <-
  lm(Height ~ Chest + Age + Sex + Belly + Thigh + Knee + Calf + Ankle + Biceps +
       Wrist + Weight ,
     data = bodymeasurements)

summary(fit_model)
```

## Question 2:
### Find the ‘best’ set of explanatory variables for the body height using Best Subset Selection. Use the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) as the selection criteria. Compare the included variables of the two resulting ‘best’ models.
```{r}
fullmodel <- lm(Height ~ ., data = bodymeasurements)
ols_step_best_subset(fullmodel)

#model6 best for BIC
#model8 best for AIC

bestBICModel <-
  lm(Height ~  Sex + Belly + Thigh + Calf + Biceps + Weight, data = bodymeasurements)

summary(bestBICModel)

bestAICModel <-
  lm(Height ~  Chest + Sex + Belly + Thigh + Calf + Biceps + Wrist +
       Weight,
     data = bodymeasurements)

summary(bestAICModel)

```
 
## Question 3:
### Estimate the ‘best’ linear model for the dependent variable w.r.t. the BIC from Task 2. Interpret the coefficients of the model and their statistical significance, provide confidence intervals for the regression parameters and evaluate the goodness of fit.

```{r}
summary(bestBICModel)

bestBICModel_res = augment(bestBICModel)

# Assumptions to check for the BIC Model

ggplot(bestBICModel_res, aes(x = .fitted, y = .resid)) + geom_point() + geom_hline(yintercept = 0) +
  xlab('Fitted values') + ylab('Residuals') + ggtitle('Residuals vs Fitted')+
  theme(
    axis.text = element_text(size = 20),
    axis.title = element_text(size = 18),
    plot.title = element_text(hjust = 0.5, size = 18)
  )

# Q-Q plot
ggplot(data = bestBICModel_res, aes(sample = .std.resid)) + stat_qq() + stat_qq_line(col = 'red') +
  ylab('Standardized residuals') + xlab('Theoretical Quantiles') + ggtitle('Normal Q-Q') +
  theme(
    axis.text = element_text(size = 20),
    axis.title = element_text(size = 18),
    plot.title = element_text(hjust = 0.5, size = 18)
  )

# estimating 95% confidence interval for estimated regression coefficients
confint(bestBICModel, level = 0.95) # estimating confidence interval for estimated regression coefficients
round(confint(bestBICModel, level = 0.95), 2)

#goodness of fit: R2
R2 <- summary(bestBICModel)[["r.squared"]]
R2
```